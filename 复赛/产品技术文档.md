# 产品技术文档

## LLM-ECO-VIZ：开源AI大模型生态分析与可视化 

## 前言

​	请读者注意，本文档的主要目的是向**开发者**全方位地展现`LLM-ECO-VIZ`项目的**项目结构**、**数据来源**、**设计思路**等**技术细节**。若只想了解如何使用本产品，请移步[产品使用文档](产品使用文档.md)。在读本文档前，请先读[产品使用文档](产品使用文档.md)深入了解本项目的实现效果。

​	为洞察大模型领域的开原生态情况，本项目基于GitHub和Hugging Face两个开源社区的活动数据，对两个社区的大模型领域开源项目进行了生态分析与可视化。从开发者的视角来看，项目的文件结构如下：

```plaintext
LLM-ECO-VIZ
├── data_fetching/         # 数据获取相关代码
│   ├── author_metadata/     # Hugging Face - 获取模型作者元数据
│   ├── fetching_model_tree/ # Hugging Face - 获取模型及其衍生关系树
│   ├── find_basemodel/      # Hugging Face - 获取基础模型数据
│   ├── llm_github_data/     # GitHub - 项目分类数据
│   ├── model_metadata/      # Hugging Face - 模型元数据获取
│   └── space_metadata/      # Hugging Face - Space相关元数据获取
├── data_hf/               # 用于处理Hugging Face数据
│   ├── graph_computing.py   # 图构建及影响力计算
│   └── data_clean.ipynb     # 数据清洗
├── frontend/              # GitHub大屏部分前端子模块
│   ├── components/     	 # React 组件
│   ├── pages/         		 # 页面路由
│   ├── public/              # 静态资源
│   ├── styles/              # 全局样式
│   ├── utils/               # 工具函数
│   ├── lib/                 # 核心库文件
│   ├── hooks/               # React hooks
│   ├── contexts/            # React contexts
│   └── data/                # 静态数据
├── viz_hf/                # Hugging Face部分子模块
│   ├── global_dashboard/    # 生态全局数据大屏后端文件
│   ├── leaderboard/         # LLM Leaderboard后端文件
│   ├── network_graph/       # 网络关系图后端文件
│   ├── static/              # 静态资源（css,js,img）
│   ├── templates/           # 前端模板
│   ├── app.py               # Flask主程序入口
│   ├── config.py            # 配置文件
│   ├── graph.pkl            # 预处理后的图数据
│   └── requirements.txt     # 后端依赖文件
└── data_migrate/          # 将GitHub数据存放到supabase

```

​	每个文件夹的具体内容可通过文件夹内的README查看。

## 目录

- [产品技术文档](#产品技术文档)
  - [LLM-ECO-VIZ：开源AI大模型生态分析与可视化](#llm-eco-viz开源ai大模型生态分析与可视化)
  - [前言](#前言)
  - [目录](#目录)
  - [一、GitHub部分](#一github部分)
    - [1. 数据获取与处理](#1-数据获取与处理)
      - [(1) OpenDigger数据接口](#1-opendigger数据接口)
      - [(2) 数据缓存策略](#2-数据缓存策略)
    - [2. 评分算法实现](#2-评分算法实现)
      - [(1) 代码质量评分实现](#1-代码质量评分实现)
      - [(2) 社区活跃度评分实现](#2-社区活跃度评分实现)
    - [3. 可视化技术实现](#3-可视化技术实现)
      - [(1) ECharts配置优化](#1-echarts配置优化)
      - [(2) 性能优化实现](#2-性能优化实现)
    - [4. 状态管理与性能优化](#4-状态管理与性能优化)
      - [(1) Context优化](#1-context优化)
      - [(2) 性能优化实践](#2-性能优化实践)
  - [二、Hugging Face部分](#二hugging-face部分)
    - [1. 数据获取](#1-数据获取)
    - [2. 用Easy Graph构造图](#2-用easy-graph构造图)
    - [3. 影响力计算](#3-影响力计算)
        - [1. 自身影响力计算](#1-自身影响力计算)
        - [Spaces 总影响力计算](#spaces-总影响力计算)
        - [2. 总影响力计算](#2-总影响力计算)
        - [公式](#公式)
        - [3. 算法迭代步骤](#3-算法迭代步骤)
        - [4. 参数说明](#4-参数说明)
    - [4. 用PyVis绘制关系网络图](#4-用pyvis绘制关系网络图)

## 一、GitHub部分

​	GitHub部分的数据来自于OpenDigger，通过 RESTful API 获取静态数据，根链接为 `https://oss.open-digger.cn/{platform}/{org/login}/{repo}/`。本部分基于 Next.js 15 + React 19 构建，采用 TypeScript 进行类型检查，使用 Material-UI 作为组件库，集成了 ECharts 进行数据可视化。

### 1. 数据获取与处理

#### (1) OpenDigger数据接口
OpenDigger提供了丰富的开源项目数据指标。我们通过以下方式实现数据获取和处理：

1. 定义统一的响应接口，确保类型安全：
```typescript
// 核心数据接口定义
interface OpenDiggerResponse<T> {
  code: number;
  message: string;
  data: T;
}

interface ProjectMetrics {
  openrank: number[];    // OpenRank指标，反映项目综合影响力
  activity: number[];    // 活跃度指标，反映项目开发活跃程度
  attention: number[];   // 关注度指标，反映项目受关注程度
  active_dates: string[]; // 活跃时间点，用于时间序列分析
}
```

2. 实现数据获取服务，支持并发请求和错误处理：
```typescript
class OpenDiggerService {
  private static BASE_URL = 'https://oss.open-digger.cn/';
  
  // 获取项目指标数据：并发请求多个指标，提高加载效率
  async getProjectMetrics(owner: string, repo: string): Promise<ProjectMetrics> {
    const endpoints = ['openrank', 'activity', 'attention'];
    const results = await Promise.all(
      endpoints.map(metric => 
        fetch(`${OpenDiggerService.BASE_URL}/${owner}/${repo}/${metric}`)
          .then(res => res.json())
      )
    );
    return this.processMetricsData(results);
  }

  // 数据预处理：清洗异常值，统一数据格式，补充缺失值
  private processMetricsData(rawData: any[]): ProjectMetrics {
    // 实现数据清洗、规范化和合并逻辑
  }
}
```

#### (2) 数据缓存策略
为提高数据加载性能，实现了基于localStorage的多级缓存策略：

1. 缓存管理器实现：
```typescript
class CacheManager {
  private static CACHE_PREFIX = 'llm_eco_viz_';
  private static CACHE_EXPIRY = 24 * 60 * 60 * 1000; // 24小时过期

  // 写入缓存：存储数据同时记录时间戳
  static setCache(key: string, data: any): void {
    const cacheItem = {
      data,
      timestamp: Date.now()
    };
    localStorage.setItem(
      this.CACHE_PREFIX + key,
      JSON.stringify(cacheItem)
    );
  }

  // 读取缓存：检查是否过期，自动清理过期数据
  static getCache(key: string): any | null {
    const cached = localStorage.getItem(this.CACHE_PREFIX + key);
    if (!cached) return null;

    const { data, timestamp } = JSON.parse(cached);
    if (Date.now() - timestamp > this.CACHE_EXPIRY) {
      localStorage.removeItem(this.CACHE_PREFIX + key);
      return null;
    }
    return data;
  }
}
```

### 2. 评分算法实现

#### (1) 代码质量评分实现
代码质量评分采用多维度加权计算方式，考虑PR处理效率、Issue解决质量等因素：

```typescript
class CodeQualityScorer {
  // PR质量评分：结合接受率和处理时间
  private calculatePRQualityScore(prData: PRMetrics): number {
    const { acceptanceRate, processingTime } = prData;
    // 使用指数衰减函数计算时间权重，处理时间越长权重越低
    const timeWeight = Math.exp(-0.1 * processingTime);
    // 70%权重给接受率，30%权重给处理时间
    return (acceptanceRate * 0.7 + timeWeight * 0.3) * 100;
  }

  // Issue解决质量：评估解决效率和完成率
  private calculateIssueQualityScore(issueData: IssueMetrics): number {
    const { resolutionTime, resolutionRate } = issueData;
    // 使用Sigmoid函数将解决时间映射到(0,1)区间
    const timeScore = 1 / (1 + Math.exp(-0.01 * resolutionTime));
    // 60%权重给解决率，40%权重给时间得分
    return (resolutionRate * 0.6 + timeScore * 0.4) * 100;
  }

  // 综合评分：整合PR、Issue和代码审查三个维度
  public calculateOverallScore(metrics: ProjectMetrics): number {
    const prScore = this.calculatePRQualityScore(metrics.pr);
    const issueScore = this.calculateIssueQualityScore(metrics.issue);
    // 40%权重给PR质量，30%权重给Issue质量，30%权重给代码审查
    return prScore * 0.4 + issueScore * 0.3 + metrics.codeReviewScore * 0.3;
  }
}
```

代码质量评分的计算公式：

1. PR质量评分：
   $$S_{PR} = (0.7 \cdot R_{accept} + 0.3 \cdot e^{-0.1t_{process}}) \cdot 100$$
   其中：
   - $R_{accept}$ 为PR接受率 (0-1)
   - $t_{process}$ 为平均处理时间（天）
   - $e^{-0.1t_{process}}$ 为时间衰减因子

2. Issue质量评分：
   $$S_{Issue} = (0.6 \cdot R_{resolve} + 0.4 \cdot \frac{1}{1 + e^{-0.01t_{resolve}}}) \cdot 100$$
   其中：
   - $R_{resolve}$ 为Issue解决率 (0-1)
   - $t_{resolve}$ 为平均解决时间（天）
   - $\frac{1}{1 + e^{-0.01t_{resolve}}}$ 为时间评分的Sigmoid映射

3. 综合评分：
   $$S_{total} = 0.4 \cdot S_{PR} + 0.3 \cdot S_{Issue} + 0.3 \cdot S_{review}$$
   其中：
   - $S_{review}$ 为代码审查评分 (0-100)

#### (2) 社区活跃度评分实现
社区活跃度评分关注项目的可持续性和社区健康度：

```typescript
class CommunityActivityScorer {
  // Bus Factor计算：评估项目对核心开发者的依赖程度
  private calculateBusFactor(contributors: ContributorData[]): number {
    const totalContributions = contributors.reduce((sum, c) => sum + c.contributions, 0);
    let cumulativeContributions = 0;
    let busFactor = 0;
    
    // 计算贡献累计超过50%所需的最少开发者数量
    for (const contributor of contributors) {
      cumulativeContributions += contributor.contributions;
      busFactor++;
      if (cumulativeContributions / totalContributions > 0.5) break;
    }
    return busFactor;
  }

  // 贡献者增长率：评估社区扩张速度
  private calculateGrowthRate(historicalData: MonthlyContributors[]): number {
    // 计算月环比增长率
    const monthlyGrowth = historicalData.map((month, i, arr) => {
      if (i === 0) return 0;
      return (month.count - arr[i-1].count) / arr[i-1].count;
    });
    // 返回平均增长率
    return monthlyGrowth.reduce((sum, rate) => sum + rate, 0) / monthlyGrowth.length;
  }
}
```

社区活跃度评分的计算公式：

1. Bus Factor计算：
   $$BF = \min\{k \mid \sum_{i=1}^k \frac{C_i}{C_{total}} > 0.5\}$$
   其中：
   - $C_i$ 为第i个贡献者的贡献量
   - $C_{total}$ 为总贡献量
   - $k$ 为最小贡献者数量

2. 贡献者增长率：
   $$G_{avg} = \frac{1}{n-1} \sum_{i=1}^{n-1} \frac{C_{i+1} - C_i}{C_i}$$
   其中：
   - $C_i$ 为第i个月的贡献者数量
   - $n$ 为总月份数

3. 社区活跃度综合评分：
   $$S_{community} = 0.4 \cdot \min(100, BF \cdot 10) + 0.3 \cdot \max(0, \min(100, G_{avg} \cdot 200 + 50)) + 0.3 \cdot S_{response}$$
   其中：
   - $BF$ 为Bus Factor值
   - $G_{avg}$ 为平均增长率
   - $S_{response}$ 为社区响应速度评分 (0-100)

### 3. 可视化技术实现

#### (1) ECharts配置优化
针对大数据量的时序图表，实现了一套优化的配置生成系统：

```typescript
class ChartConfigGenerator {
  // 生成基础配置：提供统一的图表交互功能
  private static getBaseConfig(): EChartsOption {
    return {
      tooltip: {
        trigger: 'axis',
        axisPointer: { type: 'cross' }
      },
      grid: {
        right: '5%',
        left: '5%',
        bottom: '10%'
      },
      toolbox: {
        feature: {
          dataZoom: {},    // 数据区域缩放
          restore: {},     // 重置
          saveAsImage: {}  // 保存图片
        }
      }
    };
  }

  // 时序数据图表配置：自动适应数据特征
  public static generateTimeSeriesConfig(data: TimeSeriesData): EChartsOption {
    const baseConfig = this.getBaseConfig();
    const processedData = this.preprocessTimeSeriesData(data);
    
    return {
      ...baseConfig,
      xAxis: {
        type: 'time',
        splitLine: { show: false }
      },
      yAxis: this.generateDynamicYAxis(processedData),
      series: this.generateSeries(processedData)
    };
  }
}
```

#### (2) 性能优化实现
针对大数据量可视化场景，实现了数据抽稀和动态加载策略：

```typescript
// 图表性能优化
class ChartOptimizer {
  // 数据抽稀：在保持趋势的前提下减少数据点
  private static thinningData(data: DataPoint[], threshold: number): DataPoint[] {
    if (data.length <= threshold) return data;
    
    // 等距采样，保持数据分布特征
    const step = Math.ceil(data.length / threshold);
    return data.filter((_, index) => index % step === 0);
  }

  // 动态加载：按需加载数据，支持缓存
  private static async loadChartData(
    startTime: number,
    endTime: number,
    granularity: string
  ): Promise<DataPoint[]> {
    // 优先使用缓存数据
    const cachedData = CacheManager.getCache(`chart_${startTime}_${endTime}`);
    if (cachedData) return cachedData;

    // 获取新数据并进行抽稀处理
    const data = await this.fetchChartData(startTime, endTime, granularity);
    const processedData = this.thinningData(data, 1000);
    CacheManager.setCache(`chart_${startTime}_${endTime}`, processedData);
    
    return processedData;
  }
}

// 图表更新Hook：处理图表重绘逻辑
function useChartUpdate(chartInstance: EChartsInstance, data: any) {
  useEffect(() => {
    if (!chartInstance || !data) return;
    
    // 使用防抖优化频繁更新
    const debounceUpdate = debounce((data: any) => {
      chartInstance.setOption({
        series: ChartOptimizer.thinningData(data, 1000)
      });
    }, 100);
    
    debounceUpdate(data);
    
    return () => {
      debounceUpdate.cancel();
    };
  }, [chartInstance, data]);
}
```

### 4. 状态管理与性能优化

#### (1) Context优化
使用React Context实现高效的状态管理：

```typescript
// Context定义：管理项目全局状态
const ProjectContext = createContext<ProjectContextType>({
  project: null,      // 当前项目信息
  metrics: null,      // 项目指标数据
  loading: false,     // 加载状态
  error: null,        // 错误信息
  updateProject: () => {}, // 更新项目方法
});

// Provider实现：优化重渲染性能
export function ProjectProvider({ children }: { children: React.ReactNode }) {
  const [state, dispatch] = useReducer(projectReducer, initialState);
  // 使用useMemo缓存context值，避免不必要的重渲染
  const contextValue = useMemo(() => ({
    ...state,
    updateProject: (project: Project) => 
      dispatch({ type: 'UPDATE_PROJECT', payload: project })
  }), [state]);

  return (
    <ProjectContext.Provider value={contextValue}>
      {children}
    </ProjectContext.Provider>
  );
}
```

#### (2) 性能优化实践
实现了数据预加载和虚拟列表等优化策略：

```typescript
// 数据预加载Hook：提前加载可能需要的数据
function useDataPreload(projectId: string) {
  useEffect(() => {
    const preloadData = async () => {
      // 获取相关项目列表
      const nearbyProjects = await fetchNearbyProjects(projectId);
      // 预加载相关项目数据
      nearbyProjects.forEach(project => {
        const prefetcher = new DataPrefetcher();
        prefetcher.preloadProjectData(project.id);
      });
    };
    preloadData();
  }, [projectId]);
}

// 虚拟列表：处理大量数据的高效渲染
class VirtualList {
  private static ITEM_HEIGHT = 50;  // 列表项固定高度
  private static BUFFER_SIZE = 5;   // 上下缓冲区大小

  // 计算可视区域范围
  public getVisibleRange(
    scrollTop: number,
    viewportHeight: number,
    totalItems: number
  ): [number, number] {
    // 计算起始索引
    const start = Math.floor(scrollTop / this.ITEM_HEIGHT);
    // 计算可见项数量
    const visibleCount = Math.ceil(viewportHeight / this.ITEM_HEIGHT);
    // 添加缓冲区
    const bufferedStart = Math.max(0, start - this.BUFFER_SIZE);
    const bufferedEnd = Math.min(totalItems, start + visibleCount + this.BUFFER_SIZE);
    return [bufferedStart, bufferedEnd];
  }
}
```

## 二、Hugging Face部分

### 1. 数据获取

​	我们Hugging Face上的数据的来源有两处：一为`huggingface_api`，二是通过爬虫爬取Hugging Face官网上的数据。下面我们将从数据获得的先后顺序来介绍我们的数据源的获取。所有获取数据的文件存放于`data_fetching/`中。

- `find_basemodel/` - 用`huggingface_api`获取点赞量排名前1000的模型名称
- `fetching_model_tree/` - 用爬虫获取点赞量排名前1000的模型的衍生模型
- `model_metadata/` - 用`huggingface_api`获取点赞量排名前1000的模型及其衍生模型的元数据
- `author_metadata/` - 用爬虫获取点赞量排名前1000的模型及其衍生模型的作者的元数据
- `space_metadata/` - 用爬虫获取`huggingface_api`获取相关模型space应用的元数据

各部分输出存放在各自文件夹的`output`文件夹下。

### 2. 用Easy Graph构造图

​	在`data_hf/`文件夹下，我们用Easy Graph构建起了大模型的关系图。它的本质是一个有向图。构建过程可参考`data_hf/graph_computing.py`的`build_graph()`函数。

- 一个结点表示一个模型
- 结点A指向结点B当且仅当B是A的衍生模型
- 结点的属性包括：下载量、点赞数、作者名称、作者的全名、作者的组织性质、模型创建日期、模型支持的语言、模型制作的spaces列表、模型的图标链接、作者的类型、模型的任务类型以及影响力。其中，影响力这一指标需要在整个图构建完成后再计算，后面会提到
- 边的属性包括：衍生模型的类型

### 3. 影响力计算

​	在`data_hf/graph_computing.py`中，我们设计了影响力算法。

我们的影响力算法是一个迭代过程，它结合了节点自身的属性、子节点（直接后继节点）的反馈以及父节点（直接前驱节点）的影响来评估每个节点在整个图中的影响力。这个过程考虑到了时间衰减因素，并且对不同类型的影响力分配了不同的权重。下面是该算法表达式的详细描述：


##### 1. 自身影响力计算

每个节点的自身影响力通过以下公式计算：

$$
I_{\text{self}} = W_1 \cdot \log(\max(\text{downloads}, 1)) + W_2 \cdot \text{likes} + W_3 \cdot I_{\text{spaces}} + W_4 \cdot e^{-\lambda \cdot \text{days since created}}
$$

其中：
- $I_{\text{spaces}}$ 表示节点关联的 Spaces 的总影响力。
- $W_1, W_2, W_3, W_4$ 分别为自身影响力的分项权重参数。
- $\lambda$ 为时间衰减因子。
- $\text{days since created}$ 表示节点创建至今的天数。

##### Spaces 总影响力计算

$$
I_{\text{spaces}} = \sum_{\text{space} \in \text{spaces}} \text{likes}_{\text{space}} \cdot e^{-\lambda \cdot \text{days since created space}}
$$

其中：
- $\text{likes}_{\text{space}}$ 为 Space 的点赞数。
- $\text{days since created space}$ 为 Space 创建至今的天数。

---

##### 2. 总影响力计算

每个节点的总影响力由以下三部分组成：
1. 自身影响力。
2. 子模型传播的影响力。
3. 父模型传播的影响力。

##### 公式

$$
I_{\text{total}} = \alpha_1 \cdot I_{\text{self}} + \alpha_2 \cdot I_{\text{child}} + \alpha_3 \cdot I_{\text{parent}}
$$

其中：
- $I_{\text{self}}$ 为自身影响力。
- $I_{\text{child}}$ 为子模型传播的影响力，计算公式如下：

$$
I_{\text{child}} = \frac{1}{\max(1, |\text{children}|)} \sum_{\text{child} \in \text{children}} w_{\text{child}} \cdot I_{\text{child}}
$$

  $w_{\text{child}}$ 表示从当前节点到子节点的权重。

- $I_{\text{parent}}$ 为父模型传播的影响力，计算公式如下：

$$
I_{\text{parent}} = \frac{1}{\max(1, |\text{parents}|)} \sum_{\text{parent} \in \text{parents}} w_{\text{parent}} \cdot I_{\text{parent}}
$$

  $w_{\text{parent}}$ 表示从父节点到当前节点的权重。

---

##### 3. 算法迭代步骤

1. 初始化：将每个节点的初始影响力设置为其自身影响力：
   
$$
I_{\text{initial}}(v) = I_{\text{self}}(v)
$$

2. 迭代更新影响力值：
   对每个节点，计算其新的总影响力：

$$
I_{\text{total,new}}(v) = \alpha_1 \cdot I_{\text{self}}(v) + \alpha_2 \cdot I_{\text{child}}(v) + \alpha_3 \cdot I_{\text{parent}}(v)
$$

3. 计算总误差：

$$
\text{diff} = \sum_{v \in \text{nodes}} |I_{\text{total,new}}(v) - I_{\text{total,old}}(v)|
$$

4. 判断收敛：
   如果 $\text{diff} < \text{tol}$，则认为算法收敛。

5. 更新影响力值，进入下一次迭代。

---

##### 4. 参数说明
下面介绍我们所取的参数值。

- $\alpha_1=0.6, \alpha_2=0.3, \alpha_3=0.1$：分别为自身影响力、子模型影响力、父模型影响力的权重参数。
- $W_1=0.2, W_2=0.4, W_3=0.2, W_4=0.2$：自身影响力的分项权重。
- $\lambda=1$：时间衰减因子。
- $\text{tol}=10^{-6}$：收敛误差阈值。
- $\text{max iter}=100$：最大迭代次数。

整个算法通过迭代更新每个节点的影响力直至收敛或达到最大迭代次数为止。每次迭代都会根据最新的影响力值重新计算，并检查与上一次迭代之间的差异是否小于预设阈值来判断是否停止迭代。

​	为每个结点设置好影响力后，整个图对象的构造已完毕，我们将图对象保存为`pkl`格式到`viz_hf/`文件夹中，用于后续的可视化。

### 4. 用PyVis绘制关系网络图

​	我们采用 PyVis 库进行关系网络图的可视化绘制。为了使网络图更加美观，我们设计了八种不同的筛选结点的方式。 此外，基于已有的这些数据，我们还构建了 LLM Leaderboard 以及 大模型生态大屏，将我们的项目变得更像一个生态分析的应用。这些内容都在[`viz_hf/](../viz_hf/)`文件夹中。我们使用 Flask 框架将其部署为一个 Web 应用。最终展示的实际效果请见产品使用文档！